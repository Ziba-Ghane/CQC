{"cells":[{"cell_type":"markdown","id":"bb16ef61","metadata":{"id":"bb16ef61"},"source":["# Set Variables"]},{"cell_type":"code","execution_count":null,"id":"1d473d55","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:22:35.622154Z","start_time":"2022-05-15T06:22:35.594169Z"},"id":"1d473d55"},"outputs":[],"source":["# -------- dataset\n","# software_name = \"Camel\"\n","# software_name = \"CloudStack\"\n","software_name = \"Geode\"\n","# software_name = \"Hbase\"\n","\n","token_threshold = 20000\n","\n","# --------\n","my_keyword_Based = True\n","# my_keyword_Based = False\n","\n","my_docMaxLen = 100 if my_keyword_Based else None"]},{"cell_type":"code","source":["dataset_file_names = {\n","    \"Camel\":      \"Camel_DE - v.02\",\n","    \"CloudStack\": \"CloudStack_DE - v.01\",\n","    \"Geode\":      \"Geode_DE - v.01\",\n","    \"Hbase\":      \"Hbase_DE - v.01\"\n","}\n","\n","dataset_file_name = dataset_file_names[software_name]"],"metadata":{"id":"CfCOqdrT9FCv"},"id":"CfCOqdrT9FCv","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"60798d75","metadata":{"id":"60798d75"},"source":["# Google Colab"]},{"cell_type":"code","source":["# Libs\n","!pip install --upgrade matplotlib"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVD2gVbQ9F15","executionInfo":{"status":"ok","timestamp":1655982763283,"user_tz":-270,"elapsed":6918,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"e1726961-270e-4534-8c3c-f66231020da0"},"id":"gVD2gVbQ9F15","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.5.2)\n","Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (4.33.3)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.1.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n"]}]},{"cell_type":"code","source":["# load data from google drive\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\", force_remount=True)\n","!ls \"/content/gdrive/My Drive/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ktx9VNw9HWG","executionInfo":{"status":"ok","timestamp":1655982767122,"user_tz":-270,"elapsed":3861,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"769e6040-dda8-4e95-cf34-bc8ccbda04dc"},"id":"8ktx9VNw9HWG","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n","'Colab Notebooks'\n"]}]},{"cell_type":"code","source":["# project folder path\n","project_folder = \"gdrive/MyDrive/Colab Notebooks/paper/\"\n","\n","# data folder path\n","data_folder =    \"00- My Data/one-phase method/\"\n","\n","# output folder path\n","output_folder =  \"01- Jupyter Notebook/50- one-phase method _ CNN/00. Output/\""],"metadata":{"id":"xmj_5VFU9Jdj"},"id":"xmj_5VFU9Jdj","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# dataset folder path\n","dataset_folder = software_name + \"/\"\n","\n","# output data-folder path\n","output_data_folder = project_folder + output_folder + dataset_folder + dataset_file_name + \"/\""],"metadata":{"id":"oQ8enShV9J9L"},"id":"oQ8enShV9J9L","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"a06904c1","metadata":{"id":"a06904c1"},"source":["# Libs"]},{"cell_type":"code","execution_count":null,"id":"b5844ea3","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:22:41.942558Z","start_time":"2022-05-15T06:22:35.754078Z"},"id":"b5844ea3"},"outputs":[],"source":["import string\n","import re\n","import json\n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from torchvision import transforms\n","from nltk.corpus import stopwords\n","from nltk.tokenize import WordPunctTokenizer\n","from nltk.text import TextCollection"]},{"cell_type":"code","execution_count":null,"id":"9d0015ab","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:22:41.957791Z","start_time":"2022-05-15T06:22:41.944620Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"9d0015ab","executionInfo":{"status":"ok","timestamp":1655982770079,"user_tz":-270,"elapsed":19,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"4799267e-b5a2-4303-f8b3-7c86ec2e1b8b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}],"source":["import nltk\n","nltk.download(\"stopwords\")"]},{"cell_type":"markdown","id":"a2d03d3d","metadata":{"id":"a2d03d3d"},"source":["# Config"]},{"cell_type":"code","execution_count":null,"id":"a124d3bd","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:22:42.116370Z","start_time":"2022-05-15T06:22:42.104375Z"},"id":"a124d3bd"},"outputs":[],"source":["mypaths = {\n","    \"data\": {\n","        \"dataset\":           project_folder + data_folder   + dataset_folder + dataset_file_name + \".csv\",\n","        \"w2v_word_vectors\":  project_folder + data_folder   + \"w2vGoogle.bin\"\n","    },\n","    \"output\": {\n","        \"keyword_based\": {\n","            \"tfidf_word_weights\": output_data_folder + \"tfidf-word-weights-v01.json\"\n","        }\n","    }\n","}\n","\n","preprocessing_params = {\n","    \"data\":{\n","        \"dataset\": {\n","            \"columns_name\":   [\"text\", \"bug_class_2\"],\n","            \"columns_dtype\" : {0: \"str\", 1: \"int64\"},\n","            \"bug_classes\": [0, 1]\n","        },\n","    },\n","    \"keyword_Based\": my_keyword_Based,\n","    \"docMaxLen\": my_docMaxLen,\n","}"]},{"cell_type":"markdown","id":"fd9e62a8","metadata":{"id":"fd9e62a8"},"source":["# I. Read Files"]},{"cell_type":"code","execution_count":null,"id":"c60f90b0","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:22:42.853095Z","start_time":"2022-05-15T06:22:42.150350Z"},"id":"c60f90b0"},"outputs":[],"source":["df_main = pd.read_csv(\n","    mypaths[\"data\"][\"dataset\"], \n","    names=preprocessing_params[\"data\"][\"dataset\"][\"columns_name\"], \n","    dtype=preprocessing_params[\"data\"][\"dataset\"][\"columns_dtype\"],\n","    header=None, \n","    skip_blank_lines=True\n",")"]},{"cell_type":"code","source":["len_df_main_before_compse = len(df_main)"],"metadata":{"id":"4yn2RK6w9o_B"},"id":"4yn2RK6w9o_B","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"39f184a2","metadata":{"id":"39f184a2"},"source":["# II. Compose"]},{"cell_type":"code","execution_count":null,"id":"a8b1063d","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:22:42.146353Z","start_time":"2022-05-15T06:22:42.123368Z"},"id":"a8b1063d"},"outputs":[],"source":["class Rows(object):\n","    def __init__(self, columns_name, bug_classes):\n","        self.columns_name = columns_name\n","        self.bug_classes = bug_classes\n","    \n","    \n","    def __call__(self, df):\n","        # 1. Set cells to None that have just white spaces\n","        df = df.apply(self.white_spaces_to_None_, axis=1)\n","        \n","        # 2. Delete rows that have NaN values in each of its columns\n","        df.dropna(axis=0, how=\"any\", subset=self.columns_name, inplace=True)\n","        \n","        # 3. Delete rows with class value other than [0, 1]\n","        indexNames = df[~df[\"bug_class_2\"].isin(self.bug_classes)].index\n","        df.drop(indexNames, axis=0, inplace=True)\n","        \n","        return df\n","    \n","    \n","    # set columns that just have white spaces to None\n","    def white_spaces_to_None_(self, row):\n","        for i in self.columns_name:\n","            if row[i] and len(str(row[i]).strip()) == 0:\n","                row[i] = None\n","        return row"]},{"cell_type":"markdown","source":["## obj"],"metadata":{"id":"dZ1csS_-9kao"},"id":"dZ1csS_-9kao"},{"cell_type":"code","source":["composed_pre = transforms.Compose([\n","    Rows(\n","        preprocessing_params[\"data\"][\"dataset\"][\"columns_name\"], \n","        preprocessing_params[\"data\"][\"dataset\"][\"bug_classes\"]\n","    )\n","])\n","\n","df_main = composed_pre(df_main)"],"metadata":{"id":"Mpdbh3B59jnl"},"id":"Mpdbh3B59jnl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["texts = df_main[\"text\"].tolist()\n","labels = df_main[\"bug_class_2\"].tolist()"],"metadata":{"id":"sEKOIrdMRaG_"},"id":"sEKOIrdMRaG_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["len_df_main_after_compse = len(df_main)\n","len_texts_before_token_threshold = len(texts)\n","len_labels_before_token_threshold = len(labels)"],"metadata":{"id":"wl_JkNPB9rM2"},"id":"wl_JkNPB9rM2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"len df_main before compose:\", len_df_main_before_compse)\n","print(\"len df_main after  compose:\", len_df_main_after_compse)\n","print(\"len(texts)                :\", len(texts))\n","print(\"len(labels)               :\", len(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UorcKVog9zdW","executionInfo":{"status":"ok","timestamp":1655982770575,"user_tz":-270,"elapsed":12,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"2140cf78-1cfa-4262-c984-05ff9143732f"},"id":"UorcKVog9zdW","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len df_main before compose: 3608\n","len df_main after  compose: 3608\n","len(texts)                : 3608\n","len(labels)               : 3608\n"]}]},{"cell_type":"markdown","id":"ae9c6645","metadata":{"id":"ae9c6645"},"source":["# I. Preprocessing"]},{"cell_type":"code","execution_count":null,"id":"9035eea6","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:22:43.279846Z","start_time":"2022-05-15T06:22:43.235868Z"},"id":"9035eea6"},"outputs":[],"source":["class Preprocessing():\n","    \n","    my_deleted_bug = {}\n","    \n","    docMaxLen = 0 # max keywords allowed\n","    w2vDic = {} # dic : {\"w1\": [0.1, 0.2, ...], \"w2\": [0.1, 0.3, ...], ...}\n","    paddingVector = np.zeros(300, dtype=\"float32\")\n","    bugRepTokens = [] # [[w1, w2, w3, ...], [w1, w2, ...], ...]\n","    docMaxTokenNo_org = 0\n","    docMaxTokenNo_token_threshold = 0\n","    docMaxTokenNo = 0 # max doc len after vectorization\n","    vector_tfidf = [] # array of dictinaries: [{\"w1\": 0.1, \"w2\": 0.3, ...}, {}, ...]\n","    vector_em = [] # array of matrix : [ [w1Vector, w2Vector], [], ...] \n","    \n","    \n","    def __init__(self, docMaxLen, token_threshold):\n","        self.docMaxLen = docMaxLen\n","        self.token_threshold = token_threshold\n","    \n","    \n","    # tfidf of corpuses words\n","    def load_tfidf(self, tfidf_path):\n","        with open(tfidf_path, \"r\") as filehandle:\n","            self.vector_tfidf = json.load(filehandle)\n","    \n","    \n","    def tokenize(self, texts):\n","        stop_words = set(stopwords.words(\"english\"))\n","        excludedTokens = {\"http\", \"url\", \"https\"}\n","        \n","        # self.df.columns[0] : \"description\"\n","        for i, doc in enumerate(texts):\n","            thisTokens = []\n","            doc = doc.lower()\n","            for token in WordPunctTokenizer().tokenize(doc):\n","                if (token in string.punctuation or token in stop_words or token in excludedTokens or \n","                    (not re.findall(\"\\w\", token)) or re.findall(\"\\A[0-9]\", token)):\n","                    continue\n","                thisTokens.append(token)\n","                self.w2vDic[token] = self.paddingVector\n","            if len(thisTokens) <= self.token_threshold:\n","                self.bugRepTokens.append(thisTokens)\n","                if (len(thisTokens) > self.docMaxTokenNo_token_threshold):\n","                    self.docMaxTokenNo_token_threshold = len(thisTokens)\n","            else:\n","                self.my_deleted_bug[i] = len(thisTokens)\n","                del labels[i]\n","                del self.vector_tfidf[i]\n","            if (len(thisTokens) > self.docMaxTokenNo_org):\n","                self.docMaxTokenNo_org = len(thisTokens)\n","    \n","    \n","    def loadW2V(self, w2vpath):\n","         with open(w2vpath, \"rb\") as f:\n","            header = f.readline()\n","            model_vocab_size, model_vector_size = map(int, header.split())\n","            binary_len = np.dtype(\"float32\").itemsize * model_vector_size\n","            \n","            for line_no in range(model_vocab_size):\n","                word = []\n","                while True:\n","                    ch = f.read(1)\n","                    if ch == b\" \":\n","                        break\n","                    if ch == b\"\":\n","                        raise EOFError(\"unexpected end of input; is count incorrect or file otherwise damaged?\")\n","                    if ch != b\"\\n\":\n","                        word.append(ch)\n","                word = b\"\".join(word).decode(\"utf-8\")\n","                if (word in self.w2vDic.keys()):\n","                    self.w2vDic[word] = np.frombuffer(f.read(binary_len), dtype=\"float32\")\n","                else:\n","                    f.seek(binary_len, 1)\n","    \n","    \n","    def vectorize_w2V (self, keywordBased=False):\n","        tempVec = []\n","        x = slice(0, self.docMaxLen)\n","        if keywordBased:\n","            print(\"Keyword Based\")\n","            for doc_tokens, doc_tfidf in zip(self.bugRepTokens, self.vector_tfidf):\n","                docKeywords = list(doc_tfidf.keys())[x]\n","                docAbs = [t for t in doc_tokens if t in docKeywords] # getDocAbsrtract_\n","                tempVec = [self.w2vDic[term] for term in docAbs]\n","                self.vector_em.append(tempVec)\n","                if (len(tempVec) > self.docMaxTokenNo):\n","                    self.docMaxTokenNo = len(tempVec)\n","        else:\n","            print(\"Not Keyword Based\")\n","            for doc_tokens in self.bugRepTokens:\n","                tempVec = [self.w2vDic[term] for term in doc_tokens]\n","                self.vector_em.append(tempVec)\n","                if (len(tempVec) > self.docMaxTokenNo):\n","                    self.docMaxTokenNo = len(tempVec)\n","    \n","    \n","    def padding(self):\n","        for doc in self.vector_em:\n","            if (len(doc) < self.docMaxTokenNo):\n","                doc.extend([self.paddingVector] * (self.docMaxTokenNo - len(doc)))\n","    \n","    \n","    def freeMem(self):\n","        self.w2vDic = {}\n","        self.bugRepTokens = []\n","        self.vector_tfidf = []\n","        self.vector_em = []"]},{"cell_type":"markdown","id":"c1066d59","metadata":{"id":"c1066d59"},"source":["## obj"]},{"cell_type":"code","execution_count":null,"id":"476b4c9c","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:23:46.665318Z","start_time":"2022-05-15T06:22:43.283842Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"476b4c9c","executionInfo":{"status":"ok","timestamp":1655982812100,"user_tz":-270,"elapsed":41531,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"b7e0042d-57a0-4014-eb42-71f8f57dabb0"},"outputs":[{"output_type":"stream","name":"stdout","text":["loadW2V\n","vectorize_w2V\n","Keyword Based\n"]}],"source":["ds = Preprocessing(preprocessing_params[\"docMaxLen\"], token_threshold)\n","ds.load_tfidf(mypaths[\"output\"][\"keyword_based\"][\"tfidf_word_weights\"])\n","ds.tokenize(texts)\n","\n","# --- vectorize: w2v (keywordbased or no)\n","print(\"loadW2V\")\n","ds.loadW2V(mypaths[\"data\"][\"w2v_word_vectors\"])\n","\n","print(\"vectorize_w2V\")\n","ds.vectorize_w2V(preprocessing_params[\"keyword_Based\"])\n","\n","ds.padding()"]},{"cell_type":"code","source":["len_texts_after_token_threshold = len(texts)\n","len_labels_after_token_threshold = len(labels)"],"metadata":{"id":"xjxUuFoGNJyY"},"id":"xjxUuFoGNJyY","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# See results"],"metadata":{"id":"eQSoPnCwAU4g"},"id":"eQSoPnCwAU4g"},{"cell_type":"code","source":["print(\"len df_main before compse         :\", len_df_main_before_compse)\n","\n","print(\"-\" * 50)\n","\n","# should have same values:\n","print(\"len df_main after  compse         :\", len_df_main_after_compse)\n","print(\"df_main length                    :\", len(df_main))\n","print(\"len texts  before token_threshold :\", len_texts_before_token_threshold)\n","print(\"len texts  after  token_threshold :\", len_texts_after_token_threshold)\n","print(\"len labels before token_threshold :\", len_labels_before_token_threshold)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KAnLiItFLmTS","executionInfo":{"status":"ok","timestamp":1655982812572,"user_tz":-270,"elapsed":20,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"d2059af4-25d9-43de-c515-7c34904ec8e2"},"id":"KAnLiItFLmTS","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len df_main before compse         : 3608\n","--------------------------------------------------\n","len df_main after  compse         : 3608\n","df_main length                    : 3608\n","len texts  before token_threshold : 3608\n","len texts  after  token_threshold : 3608\n","len labels before token_threshold : 3608\n"]}]},{"cell_type":"code","source":["# should have same values:\n","print(\"len labels after token_threshold :\", len_labels_after_token_threshold)\n","print(\"vector_tfidf                     :\", len(ds.vector_tfidf))\n","print(\"bugRepTokens                     :\", len(ds.bugRepTokens))\n","print(\"vector_em                        :\", len(ds.vector_em))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yk9Orwf6P79D","executionInfo":{"status":"ok","timestamp":1655982812572,"user_tz":-270,"elapsed":16,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"e3d76c77-671c-4b26-94fa-fb0df194583c"},"id":"yk9Orwf6P79D","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len labels after token_threshold : 3606\n","vector_tfidf                     : 3606\n","bugRepTokens                     : 3606\n","vector_em                        : 3606\n"]}]},{"cell_type":"code","execution_count":null,"id":"56748ef4","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:23:46.696267Z","start_time":"2022-05-15T06:23:46.665318Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"56748ef4","executionInfo":{"status":"ok","timestamp":1655982812574,"user_tz":-270,"elapsed":16,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"d64e9c51-4b71-4038-da4e-0130d20bff0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["docMaxTokenNo_org             : 160706\n","docMaxTokenNo_token_threshold : 12782\n","Max sentence length           : 10883\n","vector_em[0]                  : 10883\n"]}],"source":["print(\"docMaxTokenNo_org             :\", ds.docMaxTokenNo_org) # orginal\n","print(\"docMaxTokenNo_token_threshold :\", ds.docMaxTokenNo_token_threshold) # after applying token_threshold\n","\n","# should have same values\n","print(\"Max sentence length           :\", ds.docMaxTokenNo) # after applying keyword\n","print(\"vector_em[0]                  :\", len(ds.vector_em[0]))"]},{"cell_type":"code","execution_count":null,"id":"b767cf2a","metadata":{"ExecuteTime":{"end_time":"2022-05-15T06:23:46.713256Z","start_time":"2022-05-15T06:23:46.701272Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"b767cf2a","executionInfo":{"status":"ok","timestamp":1655982812575,"user_tz":-270,"elapsed":14,"user":{"displayName":"Ziba Ghane","userId":"08687858434532704051"}},"outputId":"eb0c2bea-a8c9-49ca-d2fc-cf642f96fd56"},"outputs":[{"output_type":"stream","name":"stdout","text":["w2vDic           : 19299\n","my_deleted_bug   : 2\n","my_deleted_bug   : {2671: 25257, 2831: 160706}\n"]}],"source":["print(\"w2vDic           :\", len(ds.w2vDic)) # vocabulary\n","print(\"my_deleted_bug   :\", len(ds.my_deleted_bug))\n","print(\"my_deleted_bug   :\", ds.my_deleted_bug)"]},{"cell_type":"code","source":[],"metadata":{"id":"nsAsqiafHjbz"},"id":"nsAsqiafHjbz","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"calc(100% - 180px)","left":"10px","top":"150px","width":"190px"},"toc_section_display":true,"toc_window_display":true},"colab":{"provenance":[],"collapsed_sections":[]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}